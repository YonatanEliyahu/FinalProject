{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1xrMZZkOwGe-8yduC7sOhQKBxa8nRQZB_",
      "authorship_tag": "ABX9TyNoa0hDNlAWOMEAeAg2js/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YonatanEliyahu/AirportManager/blob/master/Drowsiness_and_Distraction_Dedector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drowsiness and Distraction Dedector"
      ],
      "metadata": {
        "id": "PTXdzUln25L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yonatan Eliyahu - 209215938\n",
        "\n",
        "Avi Malka - 209355452\n",
        "\n",
        "As of today, most people move from place to place using their private car. There are drivers who do not take refreshment breaks and drive while tired, thus endangering themselves and the other drivers. Driving while tired is the main cause of road accidents. For these reasons, we decided to create a system that aims to alert the driver when he begins to show signs of fatigue and is distracted, thus preventing him from falling asleep at the wheel or making a mistake and the next fatal accident. Our system was built as a combination of two algorithms to detect falling asleep according to threshold values that we defined in the algorithm. The first algorithm gives an estimate for the level of fatigue based on the size of the eye opening. And the second algorithm gives an estimate for distraction based on the direction of turning the eyes in different directions. The system takes a live photo of the driver from the moment the trip begins to the end and alerts as soon as at least one of the algorithms passes the threshold value we set for it.\n",
        "The purpose of connecting the algorithms together is to obtain fast and reliable results for the driver.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Oz2Ka80bCC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NOTE!"
      ],
      "metadata": {
        "id": "0EDvmpFlcz4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The main function will printout a image of your face, and the \n",
        "\n",
        "To run the project you need to download the following files, add them to your notebook and then change thier path in the code.\n",
        "\n",
        "[File number 1](https://drive.google.com/file/d/1FNP1ag9KUANTaaPWo72jDbv00veIPsdh/view?usp=sharing) - face landmarks dedector\n",
        "\n",
        "[File number 2](https://drive.google.com/file/d/1Awy9pPmmoq5UMDgQcpdNOftsk9j_0alw/view?usp=share_link) - binary model\n",
        "\n",
        "[File number 3](https://drive.google.com/file/d/1--EoGg25h2E8BpmWXv6yebM2n_tZueLI/view?usp=sharing) - four way model\n",
        "\n",
        "[File number 4](https://drive.google.com/file/d/1zQ9hBiWtDxpafyUwJ_n1q5rzqsGyn3LM/view?usp=sharing) - alarm sound\n",
        "\n",
        "*the links may be updated once in a while- so if you got any invalid link please contact us at yonataneliyahu16@gmail.com."
      ],
      "metadata": {
        "id": "FTXQpaIspA_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ECa7SQ-L3jL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display ,Javascript\n",
        "from google.colab.output import eval_js \n",
        "from base64 import b64decode \n",
        "import cv2 \n",
        "import dlib \n",
        "import numpy as np \n",
        "from google.colab.patches import cv2_imshow \n",
        "import tensorflow as tf \n",
        "import collections\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "0oBgglXv6x5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frame capture functions\n",
        "\n",
        "This function takes a JavaScript object containing an image from a webcam, and returns an OpenCV BGR image.\n",
        "\n"
      ],
      "metadata": {
        "id": "bonEAKFnYLWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "  img = cv2.flip(img, 1)\n",
        "\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "7SElksLyYK3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function captures a frame from the user's webcam, converts it to an OpenCV BGR image, and returns the image."
      ],
      "metadata": {
        "id": "Y2i5cMU7TFs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_frame(file_name,quality=1):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  \n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data) \n",
        "  \n",
        "  return img"
      ],
      "metadata": {
        "id": "juRHdiOjYm1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crop eye from face\n",
        "\n",
        "This is a function to crop the left and right eye regions from an input image. It takes an input image and a target size as parameters, where the default size is set to (94, 94).\n",
        "\n",
        "The function uses dlib library to detect faces in the grayscale image. Then it uses the landmark predictor to detect the landmarks for the face, including the left and right eye landmarks. After that, it crops the left and right eye images from the input image using the detected eye landmarks.\n",
        "\n",
        "The function checks if the cropped eye images have a non-empty shape, and if not, it returns None. Otherwise, it resizes the cropped eye images to the target size and normalizes the pixel values to be in the range [0, 1]. Finally, it returns the left and right eye images as numpy arrays with shape (1, 94, 94, 3), that fits to the model images."
      ],
      "metadata": {
        "id": "UHCZ-TTBazQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_eyes_v3(image, target_size=(94, 94)):\n",
        "    # Load the face detector and landmark predictor\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor(\"/content/drive/MyDrive/FinalProject/shape_predictor_68_face_landmarks.dat\") # file number 1\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "    indent = np.round(height*width/20000*np.sqrt(2)).astype(int)\n",
        "\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the grayscale image\n",
        "    rects = detector(gray, 0)\n",
        "\n",
        "    # Check if any face is detected\n",
        "    if len(rects) == 0:\n",
        "        print(\"No face detected!\")\n",
        "        return None\n",
        "\n",
        "    # Initialize the output list for left and right eye images\n",
        "    left_eye_images = []\n",
        "    right_eye_images = []\n",
        "\n",
        "    # Loop over each face\n",
        "    for rect in rects:\n",
        "        # Use the landmark predictor to detect landmarks for the face\n",
        "        landmarks = predictor(gray, rect)\n",
        "\n",
        "        # Extract the left and right eye landmarks from the face\n",
        "        left_eye = landmarks.part(36).x, landmarks.part(37).y, landmarks.part(39).x, landmarks.part(40).y\n",
        "        right_eye = landmarks.part(42).x, landmarks.part(43).y, landmarks.part(45).x, landmarks.part(46).y\n",
        "\n",
        "        # Crop the left and right eyes from the input image\n",
        "        left_eye_image = image[left_eye[1]-indent:left_eye[3]+indent, left_eye[0]-indent:left_eye[2]+indent]\n",
        "        right_eye_image = image[right_eye[1]-indent:right_eye[3]+indent, right_eye[0]-indent:right_eye[2]+indent]\n",
        "\n",
        "        # Check if the cropped eye images have a non-empty shape\n",
        "        if left_eye_image.shape[0] == 0 or left_eye_image.shape[1] == 0 or right_eye_image.shape[0] == 0 or right_eye_image.shape[1] == 0:\n",
        "            print(\"Empty eye image!\")\n",
        "            return None \n",
        "\n",
        "        # Resize the cropped eye images to the target size\n",
        "        left_eye_image = cv2.resize(left_eye_image, target_size)\n",
        "        right_eye_image = cv2.resize(right_eye_image, target_size)\n",
        "\n",
        "        #display images \n",
        "        #cv2_imshow(left_eye_image)\n",
        "        #cv2_imshow(right_eye_image)\n",
        "\n",
        "        # Convert the cropped eye images to a numpy array with float values in the range [0, 1]\n",
        "        left_eye_image = left_eye_image.astype(np.float32) / 255.0\n",
        "        right_eye_image = right_eye_image.astype(np.float32) / 255.0\n",
        "\n",
        "        # Append the resized and normalized eye images to the output list\n",
        "        left_eye_images.append(left_eye_image)\n",
        "        right_eye_images.append(right_eye_image)\n",
        "\n",
        "    # Convert the list of eye images to numpy arrays\n",
        "    left_eye_images = np.array(left_eye_images)\n",
        "    right_eye_images = np.array(right_eye_images)\n",
        "\n",
        "    left_eye_image = left_eye_image.reshape((1, 94, 94, 3))\n",
        "    right_eye_image = right_eye_image.reshape((1, 94, 94, 3))\n",
        "\n",
        "    return left_eye_images, right_eye_images"
      ],
      "metadata": {
        "id": "-igVE3_wQ7ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labelling functions"
      ],
      "metadata": {
        "id": "6qpHnm0_1YK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_maxTwo_keys(d):\n",
        "    max1 = max2 = None\n",
        "    for key, value in d.items():\n",
        "      if max1 is None or value > d[max1]:\n",
        "        max2 = max1\n",
        "        max1 = key\n",
        "      elif max2 is None or value > d[max2]:\n",
        "        max2 = key\n",
        "    return max1, max2"
      ],
      "metadata": {
        "id": "NS-8K0BfsS25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function myPredict() takes in two eye images (L_eye and R_eye) and two trained models (binary_model and fourWay_model) and returns a label that represents the predicted state of the eyes.\n",
        "\n",
        "The function starts by initializing a list called predictions with four elements, where the first two elements correspond to the binary classification model's predictions for the left and right eyes, and the last two elements correspond to the four-way classification model's predictions for the left and right eyes, respectively."
      ],
      "metadata": {
        "id": "oTAWGPFXUIew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def myPredict(L_eye, R_eye,binary_model,fourWay_model):\n",
        "  predictions=[0,0,0,0]\n",
        "  predictions[0]=binary_model.predict(L_eye)[0]\n",
        "  predictions[1]=binary_model.predict(R_eye)[0]\n",
        "  predictions[2]={i: prob for i, prob in enumerate(fourWay_model.predict(L_eye)[0])}\n",
        "  predictions[3]={i: prob for i, prob in enumerate(fourWay_model.predict(R_eye)[0])}\n",
        "\n",
        " \n",
        "  if(predictions[0]>=0.75 and predictions[1]>0.75):\n",
        "    return 0 #close_eye\n",
        "  \n",
        "  Lmax1, Lmax2=find_maxTwo_keys(predictions[2]) # Lmax1 will hold the label with the highest probability,  Lmax2 will hold the label with the second highest probability\n",
        "  Rmax1, Rmax2=find_maxTwo_keys(predictions[3]) # Rmax1 will hold the label with the highest probability,  Rmax2 will hold the label with the second highest probability\n",
        "    \n",
        "  if(Lmax1==Rmax1): # if the two eyes were labeld as the same label\n",
        "    return Lmax1\n",
        "    \n",
        "     # one eye was labed as sure label and the second is almost sure\n",
        "      #example:\n",
        "      #predictions[2] = [0.05 0.75 0.15 0.05] ==> labeled as sure 1\n",
        "      #predictions[3] = [0.05 0.4 0.5 0.05] ==> labeled as 2 but second label is 1\n",
        "      #so we will aprove the predictions as 1\n",
        "    \n",
        "  if(predictions[2][Lmax1]>=0.75 and Lmax1==Rmax2): # if left eye was labels as sure label and the right eye was almost labeled the same\n",
        "    return Lmax1 \n",
        "  if(predictions[3][Rmax1]>=0.75 and Rmax1==Lmax2):  # if right eye was labels as sure label and the left eye was almost labeled the same\n",
        "    return Rmax1\n",
        "  \n",
        "  return 1"
      ],
      "metadata": {
        "id": "T_HbXuRWkR5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bold text**# Main"
      ],
      "metadata": {
        "id": "rvU44sjoZDAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  funcStates=[1,1,1,1] # will save the last four states\n",
        "  i=0\n",
        "  alarm_sound = Audio(filename=\"/content/drive/MyDrive/FinalProject/alarmFP.mp3\", autoplay=True) # change path - file number 4!\n",
        "\n",
        "  model_path = '/content/drive/MyDrive/FinalProject/binary_model_v3.h5' # change path - file number 2!\n",
        "  binary_model = tf.keras.models.load_model(model_path) #['close_look', 'open_look'] #1-close_look 0-open_look\n",
        "  \n",
        "  model_path = '/content/drive/MyDrive/FinalProject/fourWayModel_v3.h5' # change path - file number 3! \n",
        "  fourWay_model = tf.keras.models.load_model(model_path) \n",
        "\n",
        "  models_Labels = ['close_look', 'forward_look', 'left_look' , 'right_look']\n",
        "  \n",
        "  while True:\n",
        "    try:\n",
        "      filename = capture_frame('photo.jpg')\n",
        "      cv2_imshow(filename)\n",
        "      left_eye_image, right_eye_image = crop_eyes_v3(filename)\n",
        "\n",
        "      x=i%4 #the following line will help us maintain the array and keep it circling in size of four\n",
        "      funcStates[x]=myPredict(left_eye_image, right_eye_image,binary_model,fourWay_model)\n",
        "      print(models_Labels[funcStates[x]])\n",
        "      \n",
        "      count=collections.Counter(funcStates)\n",
        "\n",
        "# was labeled two times as closed eyein the four last function call      \n",
        "      if(count[0] >= 2 and funcStates[x]==0):\n",
        "        # Play the alarm sound\n",
        "        print(\"Alarm is playing...\")\n",
        "        display(alarm_sound)\n",
        "  \n",
        "# OR was labeled three times as distracted in the four last function calls\n",
        "      for label in range(2,4):\n",
        "       if(count[label]>=3 and funcStates[x]==label):\n",
        "         # Play the alarm sound                                                           \n",
        "         print(\"Alarm is playing...\")\n",
        "         display(alarm_sound)\n",
        "        \n",
        "      i+=1\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))\n",
        "      continue\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "Ab3rwMEhZCBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
